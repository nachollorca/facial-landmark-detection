# -*- coding: utf-8 -*-
"""customized_dataset_augmentation_library.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v1AG_M22mkm1iKGvM7V5D-sS8Shpr-jF

## 1.1) Importing external libraries
"""

import numpy as np
import cv2
from torch.utils.data import Dataset, DataLoader
import torch

#External imported library required for configuration parser
import configparser

# External imported library required for augmentation:
import albumentations as A

"""## 1.2) Initialization of config parser"""

config = configparser.ConfigParser()
config.read('./app/application_files/config.ini')

"""## 1.3) Loading options from configuration file"""

# Size of images
SIZE = int(config['CONSTANTS']['SIZE'])

# True if we want to reproduce the same results setting fixed seeds
reproducibility = True if config['OPTIONS']['reproducibility'] == "True" else False

"""## 1.4) Setting fixed seeds and configurations for reproducibility if option activated"""

if reproducibility:
  
  torch.backends.cudnn.deterministic = True
  torch.manual_seed(1)
  torch.cuda.manual_seed(1)
  np.random.seed(1)

"""### Auxiliary FaceKeypointDataset class"""

class FaceKeypointDataset(Dataset):
  def __init__(self, data, augmentation=False):
    # data is a panda dataframe with the first 30 columns containing the 
    # keypoints and the last column containing the images

    # extract keypoints
    raw_keypoints = data.drop(['Image'], axis=1)
    self.keypoints = []

    # extract images
    self.image_pixels = []
    for i in range(len(data)):
        # first we add the original image and the corresponding keypoints to our lists
        orig_img = np.array(data['Image'].iloc[i].split(' '), dtype='float32')
        orig_img = orig_img.reshape(SIZE, SIZE)
        # rescale image pixels such that all are in the range of 0 and 1
        orig_img = orig_img / 255.0
        self.image_pixels.append(orig_img)
        orig_keypoints = np.array(raw_keypoints.iloc[i],dtype='float32').reshape(-1,2)
        self.keypoints.append(orig_keypoints)

        # secondly, we apply data augmentation to create three additional instance:
        if augmentation:
          #Defining the transfromations we want to apply
          transformations=define_transformations()
          for j in range(3):
              # In rare cases, create_augmentedData returns 'None' if some of 
              # the transformed keypoints lie outside of the image
              try:
                new_img, new_keypoints = create_augmentedData(orig_img, orig_keypoints, SIZE, *transformations, transf_type=j)
                self.image_pixels.append(new_img)
                self.keypoints.append(new_keypoints)
              except:
                pass

    # save all images in a numpy array (current shape: (number of instances, 9216))
    self.images = np.array(self.image_pixels, dtype='float32')


  def __len__(self):
      return len(self.images)

  def __getitem__(self, index):
    # reshape image 
    image = self.images[index].reshape(1, SIZE, SIZE)

    # get the corresponding keypoints
    keypoints = self.keypoints[index]

    # we return a dictionary
    return {
        'image': torch.tensor(image, dtype=torch.float),
        'keypoints': torch.tensor(keypoints, dtype=torch.float),
    }

"""### Auxiliary Data Augmentation Functions

In the following we have defined three different transformations.

They all have in common that they do with p=1 a [ShiftScaleRotate](https://albumentations.ai/docs/api_reference/augmentations/geometric/transforms/#albumentations.augmentations.geometric.transforms.ShiftScaleRotate) Operation and with p=0.5 a [Horizontale Flip](https://albumentations.ai/docs/api_reference/augmentations/transforms/). (However, even if a ShiftScaleRotate is applied, the parameters of the different operations envolved (shifting, scaling, and rotation) are still drawn randomly, e.g. the angle of the rotation.) 

Additional all three transformations have one specific unique transformation: [Blur](https://albumentations.ai/docs/api_reference/augmentations/transforms/), [Brightness increase and Brightness decrease.](https://albumentations.ai/docs/api_reference/augmentations/transforms/)
"""

def define_transformations():
  '''
  This function creates/defines the three transformations we want to use 
  '''
  # :
  transf1 = A.Compose(
      [A.Blur(blur_limit=[1,3], p=1), 
      A.ShiftScaleRotate(rotate_limit=20,scale_limit=0.1, 
                          border_mode=cv2.BORDER_CONSTANT, p = 1),
      A.HorizontalFlip(p=0.5)], 
      keypoint_params=A.KeypointParams(format='xy')
  )

  transf2 = A.Compose(
      [A.RandomBrightnessContrast(brightness_limit=[0.1,0.25], contrast_limit=0.2,
                                  p=1), 
      A.ShiftScaleRotate(rotate_limit=20,scale_limit=0.1, 
                          border_mode=cv2.BORDER_CONSTANT, p = 1),
      A.HorizontalFlip(p=0.5)], 
      keypoint_params=A.KeypointParams(format='xy')
  )

  transf3 = A.Compose(
      [A.RandomBrightnessContrast(brightness_limit=[-0.25,-0.1], contrast_limit=0.2,
                                  p=1), 
      A.ShiftScaleRotate(rotate_limit=20,scale_limit=0.1, 
                          border_mode=cv2.BORDER_CONSTANT, p = 1),
      A.HorizontalFlip(p=0.5)], 
      keypoint_params=A.KeypointParams(format='xy')
  )

  transformations = [transf1, transf2, transf3]

  return transformations

def secure_correct_keypoints_ordering(keypoints):
  '''
  This function checks if a flip was applied. If that is the case we have to 
  reorder the keypoint coordinates. 
  To examine this we use the eye center:
  Originally, the first keypoint is the left eye center and the second keypoint
  is the right eye center. Thus, the x-coord of the left eye center
  (keypoints[0,0]) should be bigger than the right eye center (keypoints[1,0]).
  Otherwise, the image was flipped. 
  '''
  if (keypoints[0,0] < keypoints[1,0]):
    re_ordering = [1, 0, 4, 5, 2, 3, 8, 9, 6, 7, 10, 12, 11, 13, 14]
    correct_ordered_keypoints = np.zeros((15,2))
    for i in range(15):
        correct_ordered_keypoints[i] = keypoints[re_ordering[i]]
    return correct_ordered_keypoints
  else:
    return keypoints

def check_valid_keypoints(keypoints, image_size):
    '''This functions tests if all given keypoints can be used for our model
    training. This includes securing that all keypoints lie within the image
    frame and checking that there are 15 keypoints in total.'''
    enough_keypoints = keypoints.shape[0] == 15
    valid_keypoints = np.logical_and(keypoints.flatten() > 0, keypoints.flatten() < image_size).all()
    return enough_keypoints and valid_keypoints

def create_augmentedData(orig_image, orig_keypoints, image_size, *transformations, transf_type=None):
  '''This function creates a transformed image and the corresponding new 
  keypoints.'''
  if transf_type == None:
      transf_type = np.random.randint(0,len(transformations))
  
  if len(transformations)-1 < transf_type:
    return None

  transformed = transformations[transf_type](image=orig_image, keypoints=orig_keypoints)
  im = transformed['image']
  keypoints = transformed['keypoints']
  keypoints = np.array(list(map(lambda pair: [pair[0],pair[1]], keypoints)))

  # Check if all the new keypoints lie within the transformed image. 
  if not (check_valid_keypoints(keypoints, image_size)):
    return None

  # In case the transformation included a flip, we have to reorder the keypoints:
  keypoints = secure_correct_keypoints_ordering(keypoints)

  return im, keypoints